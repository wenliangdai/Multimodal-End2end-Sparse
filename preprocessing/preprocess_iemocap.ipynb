{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEMOCAP Preprocessing Script\n",
    "This script is used for generating IEMOCAP_RAW_PREPROCESSED data from the raw IEMOCAP data, you can download the raw dataset from:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(file_name):\n",
    "    vidcap = cv2.VideoCapture(file_name)\n",
    "    \n",
    "    # Read FPS\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = vidcap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    else :\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Read image data\n",
    "    success, image = vidcap.read()\n",
    "    images = []\n",
    "    while success:\n",
    "        images.append(image)\n",
    "        success, image = vidcap.read()\n",
    "    return np.stack(images), fps\n",
    "\n",
    "def parse_evaluation_transcript(eval_lines, transcript_lines):\n",
    "    metadata = {}\n",
    "    \n",
    "    # Parse Evaluation\n",
    "    for line in eval_lines:\n",
    "        if line.startswith('['):\n",
    "            tokens = line.strip().split('\\t')\n",
    "            time_tokens = tokens[0][1:-1].split(' ')\n",
    "            start_time, end_time = float(time_tokens[0]), float(time_tokens[2])\n",
    "            uttr_id, label = tokens[1], tokens[2]\n",
    "            metadata[uttr_id] = {'start_time': start_time, 'end_time': end_time, 'label': label}\n",
    "\n",
    "    # Parse Transcript\n",
    "    trans = []\n",
    "    for line in transcript_lines:\n",
    "        tokens = line.split(':')\n",
    "        uttr_id = tokens[0].split(' ')[0]\n",
    "        if '_' not in uttr_id:\n",
    "            continue\n",
    "        text = tokens[-1].strip()\n",
    "        try:\n",
    "            metadata[uttr_id]['text'] = text\n",
    "        except KeyError:\n",
    "            print(f'KeyError: {uttr_id}')\n",
    "    return metadata\n",
    "\n",
    "def retrieve_audio(signal, sr, start_time, end_time):\n",
    "    start_idx = int(sr * start_time)\n",
    "    end_idx = int(sr * end_time)\n",
    "    audio_segment = signal[start_idx:end_idx]\n",
    "    return audio_segment, sr\n",
    "\n",
    "def retrieve_video(frames, fps, start_time, end_time):\n",
    "    start_idx = int(fps * start_time)\n",
    "    end_idx = int(fps * end_time)\n",
    "    images = frames[start_idx:end_idx,:,:,:]\n",
    "    return images, fps\n",
    "\n",
    "def dump_image_audio(uttr_id, audio_segment, sr, img_segment, img_segment_L, img_segment_R, fps, out_path='./', grayscale=False):\n",
    "    out_path = f'{out_path}/{\"_\".join(uttr_id.split(\"_\")[:2])}'\n",
    "    if not os.path.exists(f'./{out_path}/{uttr_id}'):\n",
    "        os.makedirs(f'./{out_path}/{uttr_id}')\n",
    "    wavfile.write(f'./{out_path}/{uttr_id}/audio.wav', sr, audio_segment)\n",
    "    wavfile.write(f'./{out_path}/{uttr_id}/audio_L.wav', sr, audio_segment[:,0])\n",
    "    wavfile.write(f'./{out_path}/{uttr_id}/audio_R.wav', sr, audio_segment[:,1])    \n",
    "    for i in range(img_segment.shape[0]):\n",
    "#         cv2.imwrite(f'./{out_path}/{uttr_id}/image_{i}.jpg', img_segment[i,:,:,:])\n",
    "        imgL = img_segment_L[i,:,:,:]\n",
    "        imgR = img_segment_R[i,:,:,:]\n",
    "        if grayscale:\n",
    "            imgL = rgb2gray(imgL)\n",
    "            imgR = rgb2gray(imgR)\n",
    "        cv2.imwrite(f'./{out_path}/{uttr_id}/image_L_{i}.jpg', imgL)\n",
    "        cv2.imwrite(f'./{out_path}/{uttr_id}/image_R_{i}.jpg', imgR)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "def crop(imgs, target_size=224):\n",
    "    # imgs.shape = (180, 480, 360, 3)\n",
    "    _, h, w, _ = imgs.shape\n",
    "    offset_h = (h - target_size) // 2\n",
    "    offset_w = (w - target_size) // 2\n",
    "    imgs = imgs[:, offset_h:-offset_h, offset_w:-offset_w, :]\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:56, 47.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 2min 4s, total: 4min 19s\n",
      "Wall time: 3min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process multimodal data over all sessions\n",
    "# NOTE: This might take several hours to run, the time listed on this cell is for processing 5 label files\n",
    "output_path = './IEMOCAP_PREPROCESS'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "all_metas = {}\n",
    "for base_path in glob.glob('../data/IEMOCAP_full_release/Session*'):\n",
    "    avi_path = f'{base_path}/dialog/avi/DivX'\n",
    "    script_path = f'{base_path}/dialog/transcriptions'\n",
    "    wav_path = f'{base_path}/dialog/wav'\n",
    "    label_path = f'{base_path}/dialog/EmoEvaluation/'\n",
    "        \n",
    "    for eval_fname in tqdm(glob.glob(f'{label_path}/*.txt')):\n",
    "        avi_fname = f'{avi_path}/{eval_fname.split(\"/\")[-1].replace(\".txt\", \".avi\")}'\n",
    "        wav_fname = f'{wav_path}/{eval_fname.split(\"/\")[-1].replace(\".txt\", \".wav\")}'\n",
    "        script_fname = f'{script_path}/{eval_fname.split(\"/\")[-1]}'\n",
    "\n",
    "        eval_lines = open(eval_fname).readlines()\n",
    "        transcript_lines = open(script_fname).readlines()\n",
    "        sr, signal  = wavfile.read(wav_fname)\n",
    "\n",
    "        images, fps = read_video(avi_fname)\n",
    "\n",
    "        # Retrieve uttr_id, label, time, and transcript\n",
    "        metas = parse_evaluation_transcript(eval_lines, transcript_lines)\n",
    "\n",
    "        for uttr_id, metadata in metas.items():\n",
    "            # Retrieve and Store Audio\n",
    "            audio_segment, sr = retrieve_audio(signal, sr, metadata['start_time'], metadata['end_time'])\n",
    "            metadata['sr'] = sr\n",
    "\n",
    "            img_segment, fps = retrieve_video(images, fps, metadata['start_time'], metadata['end_time'])  \n",
    "            img_segment_L, img_segment_R = img_segment[:,:,:img_segment.shape[2] // 2,:], img_segment[:,:,img_segment.shape[2] // 2:,:]\n",
    "            img_segment_L = crop(img_segment_L)\n",
    "            img_segment_R = crop(img_segment_R)\n",
    "            metadata['fps'] = fps\n",
    "\n",
    "            dump_image_audio(uttr_id, audio_segment, sr, img_segment, img_segment_L, img_segment_R, fps, out_path=output_path)\n",
    "\n",
    "        # Update all metas\n",
    "        all_metas.update(metas)\n",
    "pickle.dump(all_metas, open(f'{output_path}/meta.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
